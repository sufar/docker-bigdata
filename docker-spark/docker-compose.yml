version: '3'
services:
  spark-master:
    image: bde2020/spark-master:3.2.1-hadoop3.2
    container_name: spark-master
    networks:
      - bigdata
    extra_hosts:
      - "${HOST_NAME}:${HOST_IP}"
    ports:
      - "8080:8080"
      - "7077:7077"
    environment:
      - INIT_DAEMON_STEP=setup_spark
    external_links:
      - "hive-server:hive-server"
      - "hive-metastore:hive-metastore"
      - "historyserver:historyserver"
      - "resourcemanager:resourcemanager"
      - "nodemanager:nodemanager"
  spark-worker:
    image: bde2020/spark-worker:3.2.1-hadoop3.2
    container_name: spark-worker
    networks:
      - bigdata
    extra_hosts:
      - "${HOST_NAME}:${HOST_IP}"
    depends_on:
      - spark-master
    ports:
      - "8081:8081"
      - "20000-20010:20000-20010"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
    external_links:
      - "hive-server:hive-server"
      - "hive-metastore:hive-metastore"
      - "historyserver:historyserver"
      - "resourcemanager:resourcemanager"
      - "nodemanager:nodemanager"
  spark-history-server:
    image: bde2020/spark-history-server:3.2.1-hadoop3.2
    container_name: spark-history-server
    networks:
      - bigdata
    extra_hosts:
      - "${HOST_NAME}:${HOST_IP}"
    depends_on:
      - spark-master
    ports:
      - "18081:18081"
    volumes:
      - /tmp/spark-events-local:/tmp/spark-events

networks:
  bigdata:
    external: true
